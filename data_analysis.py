#!/usr/bin/env python3

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
import os
from datetime import datetime

warnings.filterwarnings('ignore')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª–µ–π
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

class SpotifyDataAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–∞–Ω–Ω—ã—Ö Spotify –¥–ª—è –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ–π —Ä–∞–±–æ—Ç—ã"""

    def __init__(self):
        self.data = None
        self.results_dir = 'analysis_results'
        os.makedirs(self.results_dir, exist_ok=True)

    def load_data(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        print("=" * 70)
        print("üéµ –õ–ê–ë–û–†–ê–¢–û–†–ù–ê–Ø –†–ê–ë–û–¢–ê: –ê–ù–ê–õ–ò–ó –ú–£–ó–´–ö–ê–õ–¨–ù–´–• –î–ê–ù–ù–´–• SPOTIFY")
        print("=" * 70)
        
        try:
            self.data = pd.read_csv('spotify_tracks.csv')
            print(f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω: {len(self.data):,} –∑–∞–ø–∏—Å–µ–π")
            
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
            self.rename_columns()
            
            self.show_dataset_info()
            return True
            
        except FileNotFoundError:
            print("‚ùå –§–∞–π–ª spotify_tracks.csv –Ω–µ –Ω–∞–π–¥–µ–Ω")
            print("üì• –°–∫–∞—á–∏–≤–∞—é –¥–∞—Ç–∞—Å–µ—Ç...")
            return self.download_dataset()
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            return False
        
    def rename_columns(self):
        """–ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞"""
        rename_dict = {}
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—â–µ–º –∏ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        column_mapping = {
            'track_popularity': 'popularity',
            'track_name': 'name',
            'track_artist': 'artist', 
            'track_album_name': 'album',
            'duration_ms': 'duration_ms',
            'playlist_genre': 'genre'
        }
        
        for old_name, new_name in column_mapping.items():
            if old_name in self.data.columns:
                rename_dict[old_name] = new_name
        
        if rename_dict:
            self.data = self.data.rename(columns=rename_dict)
            print(f"üìù –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–æ –∫–æ–ª–æ–Ω–æ–∫: {len(rename_dict)}")

    def download_dataset(self):
        """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –µ—Å–ª–∏ –Ω–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ"""
        try:
            url = "https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-21/spotify_songs.csv"
            self.data = pd.read_csv(url)
            self.data.to_csv('spotify_tracks.csv', index=False)
            print(f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç —Å–∫–∞—á–∞–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {len(self.data):,} –∑–∞–ø–∏—Å–µ–π")
            
            self.rename_columns()
            self.show_dataset_info()
            return True
            
        except Exception as e:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç: {e}")
            print("–°–æ–∑–¥–∞—é –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç...")
            return self.create_sample_data()
    
    def create_sample_data(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        np.random.seed(42)
        n_samples = 2000
        
        data = {
            'popularity': np.random.randint(10, 100, n_samples),
            'danceability': np.random.uniform(0.2, 0.95, n_samples),
            'energy': np.random.uniform(0.3, 0.98, n_samples),
            'valence': np.random.uniform(0.1, 0.9, n_samples),
            'tempo': np.random.uniform(60, 180, n_samples),
            'genre': np.random.choice(['pop', 'rock', 'hip-hop', 'edm', 'jazz'], n_samples),
            'duration_ms': np.random.randint(120000, 360000, n_samples)
        }
        
        self.data = pd.DataFrame(data)
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç: {len(self.data):,} –∑–∞–ø–∏—Å–µ–π")
        return True
    
    def show_dataset_info(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞—Ç–∞—Å–µ—Ç–µ"""
        print("\nüìä –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –î–ê–¢–ê–°–ï–¢–ï:")
        print(f"‚Ä¢ –ó–∞–ø–∏—Å–µ–π: {len(self.data):,}")
        print(f"‚Ä¢ –ö–æ–ª–æ–Ω–æ–∫: {len(self.data.columns)}")
        print(f"‚Ä¢ –ö–æ–ª–æ–Ω–∫–∏: {', '.join(self.data.columns[:10])}{'...' if len(self.data.columns) > 10 else ''}")
        
        print("\nüî¢ –û–°–ù–û–í–ù–´–ï –°–¢–ê–¢–ò–°–¢–ò–ö–ò:")
        
        # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        numeric_cols = self.data.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            stats_df = self.data[numeric_cols].describe()
            print(stats_df)

    def prepare_data(self):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        print("\n" + "=" * 70)
        print("üîß –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê")
        print("=" * 70)
        
        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        print("\n1. –ê–ù–ê–õ–ò–ó –ü–†–û–ü–£–©–ï–ù–ù–´–• –ó–ù–ê–ß–ï–ù–ò–ô:")
        missing = self.data.isnull().sum()
        missing = missing[missing > 0]
        
        if len(missing) > 0:
            print(f"–ù–∞–π–¥–µ–Ω–æ –ø—Ä–æ–ø—É—Å–∫–æ–≤: {len(missing)} –∫–æ–ª–æ–Ω–æ–∫")
            for col, count in missing.items():
                percent = (count / len(self.data)) * 100
                print(f"  ‚Ä¢ {col}: {count} ({percent:.1f}%)")
            
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
            numeric_cols = self.data.select_dtypes(include=[np.number]).columns
            for col in numeric_cols:
                if col in missing:
                    self.data[col] = self.data[col].fillna(self.data[col].median())
            
            categorical_cols = self.data.select_dtypes(include=['object']).columns
            for col in categorical_cols:
                if col in missing:
                    self.data[col] = self.data[col].fillna('Unknown')
            
            print("‚úÖ –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã")
        else:
            print("‚úÖ –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –Ω–µ—Ç")
        
        # 2. –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        print("\n2. –°–û–ó–î–ê–ù–ò–ï –ù–û–í–´–• –ü–†–ò–ó–ù–ê–ö–û–í:")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        created_features = []
        
        # –°–æ–∑–¥–∞–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ –º–∏–Ω—É—Ç–∞—Ö
        if 'duration_ms' in self.data.columns:
            self.data['duration_min'] = self.data['duration_ms'] / 60000
            created_features.append('duration_min')
            print(f"  ‚úì –°–æ–∑–¥–∞–Ω–æ: duration_min (–¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ –º–∏–Ω—É—Ç–∞—Ö)")
        
        # –°–æ–∑–¥–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏
        if 'popularity' in self.data.columns:
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º qcut —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                unique_vals = self.data['popularity'].nunique()
                if unique_vals >= 3:
                    self.data['popularity_category'] = pd.qcut(
                        self.data['popularity'],
                        q=3,
                        labels=['–ù–∏–∑–∫–∞—è', '–°—Ä–µ–¥–Ω—è—è', '–í—ã—Å–æ–∫–∞—è']
                    )
                    created_features.append('popularity_category')
                    print(f"  ‚úì –°–æ–∑–¥–∞–Ω–æ: popularity_category (3 –∫–∞—Ç–µ–≥–æ—Ä–∏–∏)")
                else:
                    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å cut
                    self.data['popularity_category'] = pd.cut(
                        self.data['popularity'],
                        bins=3,
                        labels=['–ù–∏–∑–∫–∞—è', '–°—Ä–µ–¥–Ω—è—è', '–í—ã—Å–æ–∫–∞—è']
                    )
                    created_features.append('popularity_category')
                    print(f"  ‚úì –°–æ–∑–¥–∞–Ω–æ: popularity_category (3 –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞)")
            except Exception as e:
                print(f"  ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å popularity_category: {e}")
        
        # –°–æ–∑–¥–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Ç–∞–Ω—Ü–µ–≤–∞–ª—å–Ω–æ—Å—Ç–∏
        if 'danceability' in self.data.columns:
            try:
                self.data['danceability_category'] = pd.cut(
                    self.data['danceability'],
                    bins=[0, 0.4, 0.7, 1],
                    labels=['–ù–∏–∑–∫–∞—è', '–°—Ä–µ–¥–Ω—è—è', '–í—ã—Å–æ–∫–∞—è']
                )
                created_features.append('danceability_category')
                print(f"  ‚úì –°–æ–∑–¥–∞–Ω–æ: danceability_category")
            except Exception as e:
                print(f"  ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å danceability_category: {e}")
        
        # –°–æ–∑–¥–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é —ç–Ω–µ—Ä–≥–∏—á–Ω–æ—Å—Ç–∏
        if 'energy' in self.data.columns:
            conditions = [
                (self.data['energy'] < 0.3),
                (self.data['energy'] >= 0.3) & (self.data['energy'] < 0.7),
                (self.data['energy'] >= 0.7)
            ]
            choices = ['–ù–∏–∑–∫–∞—è', '–°—Ä–µ–¥–Ω—è—è', '–í—ã—Å–æ–∫–∞—è']
            self.data['energy_category'] = np.select(conditions, choices, default='–°—Ä–µ–¥–Ω—è—è')
            created_features.append('energy_category')
            print(f"  ‚úì –°–æ–∑–¥–∞–Ω–æ: energy_category")
        
        print(f"\n‚úÖ –°–æ–∑–¥–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(created_features)}")
        if created_features:
            print(f"–ù–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {', '.join(created_features)}")
        
        print("\nüéØ –î–ê–ù–ù–´–ï –ì–û–¢–û–í–´ –ö –ê–ù–ê–õ–ò–ó–£")
    